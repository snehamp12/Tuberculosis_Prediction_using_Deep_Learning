{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24342,"status":"ok","timestamp":1748028437522,"user":{"displayName":"Sneha Ilager","userId":"02947125505525035169"},"user_tz":-330},"id":"_yfHHac1kHb7","outputId":"650788d8-8a6a-47da-d979-c1b2cef23dfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fEVN923TnIiF","outputId":"f5998a40-cd97-47a8-c7c8-69ed05d19d3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Using device: cpu\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/15 - Training: 100%|██████████| 53/53 [03:23<00:00,  3.84s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1/15 — Train Loss: 0.8664, Train Acc: 61.19%, Val Loss: 0.8201, Val Acc: 63.06%, Time: 242.21s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/15 - Training: 100%|██████████| 53/53 [03:19<00:00,  3.76s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 2/15 — Train Loss: 0.6330, Train Acc: 75.95%, Val Loss: 0.6307, Val Acc: 75.28%, Time: 237.80s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 3/15 — Train Loss: 0.5582, Train Acc: 79.76%, Val Loss: 0.4971, Val Acc: 82.50%, Time: 230.83s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 4/15 — Train Loss: 0.5145, Train Acc: 81.07%, Val Loss: 0.4763, Val Acc: 82.22%, Time: 235.00s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/15 - Training: 100%|██████████| 53/53 [03:12<00:00,  3.63s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 5/15 — Train Loss: 0.5017, Train Acc: 80.95%, Val Loss: 0.4529, Val Acc: 82.50%, Time: 230.90s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 6/15 — Train Loss: 0.4670, Train Acc: 82.68%, Val Loss: 0.4749, Val Acc: 82.22%, Time: 230.10s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 7/15 — Train Loss: 0.4457, Train Acc: 83.10%, Val Loss: 0.4503, Val Acc: 82.78%, Time: 230.06s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/15 - Training: 100%|██████████| 53/53 [03:12<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 8/15 — Train Loss: 0.4179, Train Acc: 84.88%, Val Loss: 0.4379, Val Acc: 83.06%, Time: 230.49s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 9/15 — Train Loss: 0.4222, Train Acc: 84.40%, Val Loss: 0.4159, Val Acc: 85.28%, Time: 230.20s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 10/15 — Train Loss: 0.4244, Train Acc: 83.63%, Val Loss: 0.3705, Val Acc: 87.78%, Time: 230.07s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 11/15 — Train Loss: 0.4244, Train Acc: 84.52%, Val Loss: 0.4146, Val Acc: 83.33%, Time: 229.93s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 12/15 — Train Loss: 0.4165, Train Acc: 84.11%, Val Loss: 0.4009, Val Acc: 84.17%, Time: 229.81s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 13/15 — Train Loss: 0.3873, Train Acc: 86.49%, Val Loss: 0.3852, Val Acc: 84.72%, Time: 228.78s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 14/15 — Train Loss: 0.3877, Train Acc: 85.12%, Val Loss: 0.3888, Val Acc: 83.89%, Time: 229.23s\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/15 - Training: 100%|██████████| 53/53 [03:11<00:00,  3.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 15/15 — Train Loss: 0.3950, Train Acc: 84.58%, Val Loss: 0.3683, Val Acc: 85.28%, Time: 229.25s\n","\n","✅ Model saved to: resnet16_epoch5.pth\n"]},{"ename":"TypeError","evalue":"Object of type int64 is not JSON serializable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b693b7ef5a30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRICS_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Metrics saved to: {METRICS_FILE}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    181\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"]}],"source":["import os\n","import json\n","import time\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, random_split\n","from tqdm import tqdm\n","\n","# -----------------------------\n","# Device & Paths\n","# -----------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"✅ Using device: {device}\")\n","\n","DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/tb_data'\n","MODEL_SAVE_PATH = \"resnet16_epoch5.pth\"\n","METRICS_FILE = \"resnet16_metrics.json\"\n","\n","BATCH_SIZE = 32\n","IMG_SIZE = 224\n","EPOCHS = 15\n","\n","# -----------------------------\n","# Data Transforms\n","# -----------------------------\n","transform = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n","class_names = dataset.classes\n","\n","train_size = int(0.7 * len(dataset))\n","val_size = int(0.15 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n","test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n","\n","# -----------------------------\n","# Model Setup: ResNet18\n","# -----------------------------\n","resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","for param in resnet.parameters():\n","    param.requires_grad = False\n","\n","# Replace the final fully connected layer\n","resnet.fc = nn.Linear(resnet.fc.in_features, len(class_names))\n","model = resnet.to(device)\n","\n","# -----------------------------\n","# Loss and Optimizer\n","# -----------------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","# -----------------------------\n","# Training Loop\n","# -----------------------------\n","train_losses, val_losses, train_accs, val_accs, epoch_times = [], [], [], [], []\n","\n","for epoch in range(EPOCHS):\n","    start_time = time.time()\n","    model.train()\n","    total_loss, correct, total = 0.0, 0, 0\n","\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = total_loss / len(train_loader)\n","    train_accuracy = 100 * correct / total\n","    train_losses.append(train_loss)\n","    train_accs.append(train_accuracy)\n","\n","    # -----------------------------\n","    # Validation\n","    # -----------------------------\n","    model.eval()\n","    val_loss, val_correct, val_total = 0.0, 0, 0\n","\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_loss += loss.item()\n","            _, preds = torch.max(outputs, 1)\n","            val_correct += (preds == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_loss / len(val_loader)\n","    val_accuracy = 100 * val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accs.append(val_accuracy)\n","\n","    end_time = time.time()\n","    epoch_times.append(end_time - start_time)\n","\n","    print(f\"\\nEpoch {epoch+1}/{EPOCHS} — \"\n","          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n","          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, \"\n","          f\"Time: {epoch_times[-1]:.2f}s\")\n","\n","# -----------------------------\n","# Final Test Evaluation (with confidence scores)\n","# -----------------------------\n","model.eval()\n","all_preds = []\n","all_targets = []\n","all_confidences = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        probs = torch.softmax(outputs, dim=1)  # Get class probabilities\n","        confidences, preds = torch.max(probs, 1)  # Confidence = max probability\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_targets.extend(labels.numpy())\n","        all_confidences.extend(confidences.cpu().numpy())\n","\n","# -----------------------------\n","# Save Model & Metrics\n","# -----------------------------\n","torch.save(model.state_dict(), MODEL_SAVE_PATH)\n","print(f\"\\n✅ Model saved to: {MODEL_SAVE_PATH}\")\n","\n","metrics = {\n","    \"train_loss\": train_losses,\n","    \"val_loss\": val_losses,\n","    \"train_acc\": train_accs,\n","    \"val_acc\": val_accs,\n","    \"epoch_times\": epoch_times,\n","    \"predictions\": all_preds,\n","    \"targets\": all_targets,\n","    \"confidences\": all_confidences,\n","    \"class_names\": class_names\n","}\n","\n","with open(METRICS_FILE, \"w\") as f:\n","    json.dump(metrics, f)\n","\n","print(f\"✅ Metrics saved to: {METRICS_FILE}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fePVStM_vO_A"},"outputs":[],"source":["import numpy as np\n","\n","# Convert any numpy types to native Python types\n","def convert_to_native(obj):\n","    if isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif isinstance(obj, (np.int64, np.int32, np.integer)):\n","        return int(obj)\n","    elif isinstance(obj, (np.float64, np.float32, np.floating)):\n","        return float(obj)\n","    elif isinstance(obj, list):\n","        return [convert_to_native(i) for i in obj]\n","    elif isinstance(obj, dict):\n","        return {k: convert_to_native(v) for k, v in obj.items()}\n","    else:\n","        return obj\n","\n","# Apply conversion\n","metrics = convert_to_native(metrics)\n","\n","# Save as JSON\n","with open(METRICS_FILE, \"w\") as f:\n","    json.dump(metrics, f)\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1Qk7TMeNmGdJSiVLm1B95_O2PKJlvmOXn","authorship_tag":"ABX9TyN6gabqYcHGahQVyfbMYA1v"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}